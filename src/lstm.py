#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
lstm.py - A LSTM for modeling temperature anomaly. Code partially generated by ChatGPT
author: Bill Thompson
license: GPL 3
copyright: 2023-11-14
"""
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import sys
import copy
import numpy as np

# The LSTM model
class LSTM(nn.Module):
    def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:
        """ 
        initialize LSTM net

        Parameters
        ----------
        input_size : int
            size of input to NN
        hidden_size : int
            hidden layer size
        output_size : int
            NN output size
        """
        super(LSTM, self).__init__()
        self.hidden_size = hidden_size
        self.lstm = nn.LSTM(input_size, hidden_size)
        self.linear = nn.Linear(hidden_size, output_size)

    def forward(self, input: torch.tensor) -> torch.tensor:
        """
        run the model for one step

        Parameters
        ----------
        input : torch.tensor
            current input tensor, input to LSTM layer

        Returns
        -------
        torch.tensor
            NN output, size linear output layer
        """
        output, _ = self.lstm(input)
        output = self.linear(output)
        return output[-1]

# The dataset and dataloader
class TemperatureDataset(Dataset):
    def __init__(self, data: torch.tensor, seq_len: int) -> None:
        """
        a loader for the temerature anomaly data

        Parameters
        ----------
        data : torch.tensor
            the anamaly data tensor
        seq_len : int
            the size of the input tensor to return, must be the same size as input to LSTM layer
        """
        self.data = data
        self.seq_len = seq_len

    def __len__(self) -> int:
        """
        Returns
        -------
        int
            effective size of teh dataset
        """
        return len(self.data) - self.seq_len

    def __getitem__(self, idx) -> tuple[torch.tensor, torch.tensor]:
        """
        return subset fron data

        Parameters
        ----------
        idx : _type_
            index of start location within data

        Returns
        -------
        tuple[torch.tensor, torch.tensor]
            seq_len tensor starting at idx and data at seq_len
        """
        return self.data[idx:idx+self.seq_len], self.data[idx+self.seq_len]

def main():
    # set up dataframes
    datafile = 'ChatGPT/data/HadCRUT.5.0.1.0.analysis.summary_series.global.monthly.csv'

    # Get traing data and some data for prediction
    df_orig = pd.read_csv(datafile)
    df_orig['Year'] = [int(x.split('-')[0]) for x in df_orig['Time']]
    df_orig['Month'] = [int(x.split('-')[1]) for x in df_orig['Time']]
    df_orig = df_orig[['Time', 'Year', 'Month', 'Anomaly (deg C)']]
    df = df_orig[df_orig['Year'] >= 1850]      # training data
    df = df_orig[df_orig['Year'] <= 2020]
    df_pred = df_orig[df_orig['Year'] > 2020]  # data for future predictions
    
    data = torch.tensor(df['Anomaly (deg C)'].values, dtype=torch.float32)

    # LSTM parameters
    seq_len = 12  # Use a sequence length of 12 months
    dataset = TemperatureDataset(data, seq_len)
    dataloader = DataLoader(dataset, batch_size=1)

    input_size = seq_len
    hidden_size = 32
    output_size = 1
    lr = 0.001
    num_epochs = 100

    # build the model
    model = LSTM(input_size, hidden_size, output_size)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    # training
    best_model = None
    best_train_pred = None
    min_loss = sys.maxsize
    for epoch in range(num_epochs):
        epoch_loss = []
        train_pred = [0] * seq_len
        for X, y in dataloader:
            optimizer.zero_grad()
            y_pred = model(X)
            train_pred.append(y_pred.item())
            loss = criterion(y_pred, y)
            epoch_loss.append(loss.item())
            loss.backward()
            optimizer.step()
        epoch_loss = np.mean(np.array(epoch_loss))
        if epoch_loss < min_loss:
            min_loss = epoch_loss
            best_model = copy.deepcopy(model)
            best_train_pred = list(train_pred)
        if epoch % 10 == 0:
            print(f'epoch {epoch}: train - {round(epoch_loss, 4)}')
    print(f'epoch {epoch}: train - {round(epoch_loss, 4)}')

    # Predict future values
    # future = 24  # Predict 24 months into the future
    future = df_pred.shape[0]  # Predict the future
    predictions = []
    with torch.no_grad():
        best_model.eval()
        for i in range(future):
            X = data[-seq_len:].view(1, -1)
            y_pred = best_model(X)
            predictions.append(y_pred.item())
            data = torch.cat([data, y_pred.view(-1)])

    # Plot the data and predictions
    fig, ax = plt.subplots()
    ticks = list(range(0, df_orig.shape[0], 120))
    tick_labels = [df_orig['Time'][x] for x in range(0, df_orig.shape[0], 120)]
    ax.plot(df_orig['Time'], df_orig['Anomaly (deg C)'], 'o', label='Temperature Anomaly')
    ax.set_xticks(ticks, tick_labels, rotation = 45)
    ax.plot(df['Time'], best_train_pred, label = 'Training')
    ax.plot(df_pred['Time'], predictions, label='Predictions')
    ax.set_title('Global Temperature Anomaly (1850-2023)')
    ax.set_xlabel('Year')
    ax.set_ylabel('Temperature Anomaly (Â°C)')
    ax.legend()
    plt.show()

if __name__ == "__main__":
    main()
